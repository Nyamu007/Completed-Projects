{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nyamu007/Completed-Projects/blob/main/MVGCV_Lane_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lane Detection and Recognition\n",
        "\n",
        "Lane detection, recognition and segmentation are pivotal problems in the automotive industry as mainstream autonomous vehicles (AV) teeter on the precipice of market penetration. This code introduces a lane detection method based on classical computer vision techniques which performs robustly on a variety of lane-hand drive Irish roads. Data is extracted from a video stream frame-by-frame, filtered and processed to find likely lane markings and graphically represents these markings on the original frames."
      ],
      "metadata": {
        "id": "Zd7HHVjTC9pc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "colab_path = '/content/drive/'\n",
        "video_path = colab_path + 'MyDrive/MVGCV/'\n",
        "drive.mount(colab_path)"
      ],
      "metadata": {
        "id": "7HBrrk5IFVZT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "ec59af2b-40ae-4c85-8b86-7eaa0780034f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-66681794.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcolab_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvideo_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolab_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'MyDrive/MVGCV/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolab_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1TS8zob7zS0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pylab as plt\n",
        "import cv2\n",
        "import math\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video = cv2.VideoCapture(video_path + 'DualcarriagewayAndTown.mp4')\n",
        "\n",
        "# Check if video opened successfully\n",
        "if (video.isOpened()== False):\n",
        "    print(\"Error opening Video\")"
      ],
      "metadata": {
        "id": "BrSnU8yq_7k-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "# ret, frame = video.read()\n",
        "ret = video.set( 1, 5000)\n",
        "ret, frame = video.read()\n",
        "\n",
        "if ret == True:\n",
        "    cv2_imshow(frame)\n"
      ],
      "metadata": {
        "id": "l4kQcKfVE00j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ysize,xsize = frame.shape[0:2]\n",
        "\n",
        "# Create a trapezoidal area of interest\n",
        "og_dx1 = int(0.0 * xsize)\n",
        "og_dx2 = int(0.4 * xsize)\n",
        "\n",
        "og_dy1  = int(0.5 * ysize)\n",
        "og_dy2  = int(0.93 * ysize)\n",
        "# calculate vertices for polygon of interest\n",
        "vertices = np.array([[(og_dx1, ysize),\n",
        "                      (og_dx1, og_dy2),\n",
        "                      (og_dx2, og_dy1),\n",
        "                      (xsize - og_dx2, og_dy1),\n",
        "                      (xsize - og_dx1, og_dy2),\n",
        "                      (xsize - og_dx1, ysize)\n",
        "                      ]], dtype=np.int32)\n",
        "\n",
        "# Define a blank mask\n",
        "mask = np.zeros_like(frame)\n",
        "\n",
        "# Fill in pixels inside the trapezoid\n",
        "cv2.fillPoly(mask, vertices, color=(255,255,255))\n",
        "\n",
        "# Mask the trapezoidal area\n",
        "trapped_image = cv2.bitwise_and(frame, mask)\n",
        "cv2_imshow(trapped_image)"
      ],
      "metadata": {
        "id": "9qtABOXUYL3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grey = cv2.cvtColor(trapped_image,cv2.COLOR_BGR2GRAY)\n",
        "# blur = cv2.GaussianBlur(gray,(1,1),1000)\n",
        "\n",
        "sobel_x_filter = cv2.Sobel(grey, ddepth=-1, dx=1, dy=0, scale=1, borderType=cv2.BORDER_DEFAULT)\n",
        "sobel_y_filter = cv2.Sobel(grey, ddepth=-1, dx=0, dy=1, scale=1, borderType=cv2.BORDER_DEFAULT)\n",
        "\n",
        "# scharr_x_filter = cv2.Scharr(grey, ddepth=-1, dx=1, dy=0, scale=1, borderType=cv2.BORDER_DEFAULT)\n",
        "# scharr_y_filter = cv2.Scharr(grey, ddepth=-1, dx=0, dy=1, scale=1, borderType=cv2.BORDER_DEFAULT)\n",
        "\n",
        "\n",
        "sobel_filter = sobel_x_filter + sobel_y_filter\n",
        "# scharr_filter = scharr_x_filter + scharr_y_filter\n",
        "cv2_imshow(sobel_filter)\n",
        "# cv2_imshow(scharr_filter)"
      ],
      "metadata": {
        "id": "qH0V2r87S047"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hls_frame = cv2.cvtColor(trapped_image,cv2.COLOR_BGR2HLS)\n",
        "\n",
        "hls_mask = cv2.inRange(hls_frame, (0,160,0), (359,255,255))\n",
        "\n",
        "hls_masked_image = cv2.bitwise_and(frame,frame, mask=hls_mask)\n",
        "cv2_imshow(hls_masked_image)"
      ],
      "metadata": {
        "id": "aegc2YZdWT1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hls_grey = cv2.cvtColor(hls_masked_image,cv2.COLOR_BGR2GRAY)\n",
        "combined_image = cv2.bitwise_and(sobel_filter, hls_grey)\n",
        "# cv2_imshow(combined_image)"
      ],
      "metadata": {
        "id": "Jld2H3Mebhmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepocess\n",
        "# gray = cv2.cvtColor(combined_image,cv2.COLOR_BGR2GRAY)\n",
        "blur = cv2.GaussianBlur(combined_image,(1,1),1000)\n",
        "flag, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "# Taking a matrix of size 2 as the kernel\n",
        "kernel = np.ones((2,2), np.uint8)\n",
        "\n",
        "# The first parameter is the original image,\n",
        "# kernel is the matrix with which image is\n",
        "# convolved and third parameter is the number\n",
        "# of iterations, which will determine how much\n",
        "# you want to erode/dilate a given image.\n",
        "img_erosion = cv2.erode(thresh, kernel, iterations=1)\n",
        "img_dilation = cv2.dilate(img_erosion, kernel, iterations=1)\n",
        "img_erosion1 = cv2.erode(img_dilation, kernel, iterations=1)\n",
        "img_dilation2 = cv2.dilate(img_erosion1, kernel, iterations=1)\n",
        "# img_erosion2 = cv2.erode(img_dilation2, kernel, iterations=1)\n",
        "# img_dilation3 = cv2.dilate(img_erosion2, kernel, iterations=1)\n",
        "# img_erosion3 = cv2.erode(img_dilation3, kernel, iterations=1)\n",
        "\n",
        "\n",
        "# cv2_imshow(combined_image)\n",
        "# cv2_imshow(img_dilation2)"
      ],
      "metadata": {
        "id": "P8gEiYDLo4-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a smaller trapezoidal area of interest\n",
        "dx1 = int(0.00 * xsize)\n",
        "dx2 = int(0.41 * xsize)\n",
        "dy  = int(0.51 * ysize)\n",
        "\n",
        "step_factor = 0.5\n",
        "step_offset = ((og_dx2 - dx2)**2 + (og_dy1-dy)**2)**0.5\n",
        "\n",
        "og_dy2  = int(0.93 * ysize)\n",
        "\n",
        "# calculate vertices for augmented trapezoid\n",
        "shrunk_vertices = np.array([[(dx1,                                        ysize),\n",
        "                             (dx1,                                        og_dy2),\n",
        "                             (og_dx2*step_factor,                         (ysize-og_dy1)/2+og_dy1),\n",
        "                            #  (og_dx2*step_factor + step_offset,           (ysize-og_dy)/2+og_dy),\n",
        "                             (dx2,                                        dy),\n",
        "                             (xsize - dx2,                                dy),\n",
        "                            #  (xsize - og_dx2*step_factor - step_offset,   (ysize-og_dy)/2+og_dy),\n",
        "                             (xsize - og_dx2*step_factor,                 (ysize-og_dy1)/2+og_dy1),\n",
        "                             (xsize - dx1,                                og_dy2),\n",
        "                             (xsize - dx1,                                ysize)\n",
        "                             ]], dtype=np.int32)\n",
        "\n",
        "\n",
        "# Find Edges and Apply Hough Transform for lines\n",
        "edges = cv2.Canny(img_dilation2,0,255,apertureSize = 3)\n",
        "lines = cv2.HoughLinesP(edges,1,np.pi/180,50,minLineLength=20,maxLineGap=50)\n",
        "\n",
        "img = trapped_image.copy()\n",
        "final_lines = []\n",
        "\n",
        "# Plot all lines in red\n",
        "for line in lines:\n",
        "    x1,y1,x2,y2 = line[0]\n",
        "    cv2.line(img,(x1,y1),(x2,y2),(0,0,255),2)\n",
        "\n",
        "# Plot filtered lines in green\n",
        "for line in lines:\n",
        "    x1,y1,x2,y2 = line[0]\n",
        "    if (0 <= cv2.pointPolygonTest(shrunk_vertices, (float(x1),float(y1)), True)) and (0 <= cv2.pointPolygonTest(shrunk_vertices, (float(x2),float(y2)), True)):\n",
        "      cv2.line(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
        "      final_lines.append(line)\n",
        "\n",
        "# Plot Polyline filter in blue\n",
        "cv2.polylines(img,shrunk_vertices,True,(255,0,0),2)\n",
        "\n",
        "cv2_imshow(img)"
      ],
      "metadata": {
        "id": "_dP9bNaVWuBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CACHE_LEFT_SLOPE = 0\n",
        "CACHE_RIGHT_SLOPE = 0\n",
        "CACHE_LEFT = [0, 0, 0]\n",
        "CACHE_RIGHT = [0, 0, 0]\n",
        "\n",
        "drawn_img = np.zeros_like(frame)\n",
        "\n",
        "draw_lines(drawn_img, final_lines, (255,0,0), (0,0,255))\n",
        "\n",
        "processed_img = cv2.addWeighted(frame, 0.8, drawn_img, 1, 0)\n",
        "\n",
        "cv2_imshow(processed_img)"
      ],
      "metadata": {
        "id": "6PBzV68Mpmom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_lines(img, lines,color_left,color_right,thickness=12):\n",
        "\n",
        "    global CACHE_LEFT_SLOPE\n",
        "    global CACHE_RIGHT_SLOPE\n",
        "    global CACHE_LEFT\n",
        "    global CACHE_RIGHT\n",
        "\n",
        "    # DECLARE VARIABLES\n",
        "    cache_weight = 0.9\n",
        "\n",
        "    right_ys = []\n",
        "    right_xs = []\n",
        "    right_slopes = []\n",
        "\n",
        "    left_ys = []\n",
        "    left_xs = []\n",
        "    left_slopes = []\n",
        "\n",
        "    r_thresh = img.shape[1] *.4\n",
        "    l_thresh = img.shape[1] *.6\n",
        "\n",
        "    bottom_of_image = img.shape[0]\n",
        "\n",
        "    for line in lines:\n",
        "        for x1,y1,x2,y2 in line:\n",
        "            slope, yint = np.polyfit((x1, x2), (y1, y2), 1)\n",
        "            # Filter lines using slope and x position\n",
        "            if .3 < np.absolute(slope) <= 3:\n",
        "                if slope > 0 and x1 > r_thresh and x2 > r_thresh:\n",
        "                    right_ys.append(y1)\n",
        "                    right_ys.append(y2)\n",
        "                    right_xs.append(x1)\n",
        "                    right_xs.append(x2)\n",
        "                    right_slopes.append(slope)\n",
        "                elif slope < 0 and x1 < l_thresh and x2 < l_thresh:\n",
        "                    left_ys.append(y1)\n",
        "                    left_ys.append(y2)\n",
        "                    left_xs.append(x1)\n",
        "                    left_xs.append(x2)\n",
        "                    left_slopes.append(slope)\n",
        "\n",
        "\n",
        "    # DRAW RIGHT LANE LINE\n",
        "    if right_ys:\n",
        "        right_index = right_ys.index(min(right_ys))\n",
        "        right_x1 = right_xs[right_index]\n",
        "        right_y1 = right_ys[right_index]\n",
        "        right_slope = np.median(right_slopes)\n",
        "        if CACHE_RIGHT_SLOPE != 0:\n",
        "            right_slope = right_slope + (CACHE_RIGHT_SLOPE - right_slope) * cache_weight\n",
        "\n",
        "        right_x2 = int(right_x1 + (bottom_of_image - right_y1) / right_slope)\n",
        "\n",
        "        if CACHE_RIGHT_SLOPE != 0:\n",
        "            right_x1 = int(right_x1 + (CACHE_RIGHT[0] - right_x1) * cache_weight)\n",
        "            right_y1 = int(right_y1 + (CACHE_RIGHT[1] - right_y1) * cache_weight)\n",
        "            # right_x2 = int(right_x2 + (CACHE_RIGHT[2] - right_x2) * cache_weight)\n",
        "\n",
        "        length = ((right_x1-right_x2)**2+(bottom_of_image-right_y1)**2)**0.5\n",
        "        # print(length)\n",
        "        if (250 > length):\n",
        "          phi = math.atan(right_slope)\n",
        "          right_y1 = int(bottom_of_image - 250*math.sin(phi))\n",
        "          right_x1 = int(right_x2 - 250*math.cos(phi))\n",
        "\n",
        "        CACHE_RIGHT_SLOPE = right_slope\n",
        "        CACHE_RIGHT = [right_x1, right_y1, right_x2]\n",
        "\n",
        "\n",
        "\n",
        "    # DRAW LEFT LANE LINE\n",
        "    if left_ys:\n",
        "        left_index = left_ys.index(min(left_ys))\n",
        "        left_x1 = left_xs[left_index]\n",
        "        left_y1 = left_ys[left_index]\n",
        "        left_slope = np.median(left_slopes)\n",
        "        if CACHE_LEFT_SLOPE != 0:\n",
        "            left_slope = left_slope + (CACHE_LEFT_SLOPE - left_slope) * cache_weight\n",
        "\n",
        "        left_x2 = int(left_x1 + (bottom_of_image - left_y1) / left_slope)\n",
        "\n",
        "        if CACHE_LEFT_SLOPE != 0:\n",
        "            left_x1 = int(left_x1 + (CACHE_LEFT[0] - left_x1) * cache_weight)\n",
        "            left_y1 = int(left_y1 + (CACHE_LEFT[1] - left_y1) * cache_weight)\n",
        "            left_x2 = int(left_x2 + (CACHE_LEFT[2] - left_x2) * cache_weight)\n",
        "\n",
        "        CACHE_LEFT_SLOPE = left_slope\n",
        "        CACHE_LEFT = [left_x1, left_y1, left_x2]\n",
        "\n",
        "    # Interception code\n",
        "    if left_ys and right_ys:\n",
        "        x_intersect = (left_slope*left_x2 - right_slope*right_x2)/(left_slope - right_slope)\n",
        "        y_intersect = left_slope*(x_intersect - left_x2) + bottom_of_image\n",
        "\n",
        "        left_int_length = ((left_x2-x_intersect)**2+(bottom_of_image-y_intersect)**2)**0.5\n",
        "        right_int_length = ((right_x2-x_intersect)**2+(bottom_of_image-y_intersect)**2)**0.5\n",
        "\n",
        "        left_length = ((left_x1-left_x2)**2+(bottom_of_image-left_x1)**2)**0.5\n",
        "        right_length = ((right_x1-right_x2)**2+(bottom_of_image-right_y1)**2)**0.5\n",
        "\n",
        "        if (left_int_length >= left_length):\n",
        "          phi = math.atan(left_slope)\n",
        "          left_y1 = int(bottom_of_image + left_int_length*0.8*math.sin(phi))\n",
        "          left_x1 = int(left_x2 + left_int_length*0.8*math.cos(phi))\n",
        "\n",
        "        print(right_length)\n",
        "        if (right_int_length <= right_length):\n",
        "          phi = math.atan(right_slope)\n",
        "          right_y1 = int(bottom_of_image - right_int_length*0.8*math.sin(phi))\n",
        "          right_x1 = int(right_x2 - right_int_length*0.8*math.cos(phi))\n",
        "\n",
        "    if left_ys:\n",
        "      cv2.line(img, (left_x1, left_y1), (left_x2, bottom_of_image), color_left, thickness)\n",
        "    if right_ys:\n",
        "      cv2.line(img, (right_x1, right_y1), (right_x2, bottom_of_image), color_right, thickness)"
      ],
      "metadata": {
        "id": "YzwWgDdqphNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video.release()\n",
        "# Closes all the frames\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "ISTKIenUFBEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ysize,xsize = frame.shape[0:2]\n",
        "\n",
        "# Create a trapezoidal area of interest\n",
        "dx1 = int(0.0 * xsize)\n",
        "dx2 = int(0.4 * xsize)\n",
        "dy = int(0.4 * ysize)\n",
        "# calculate vertices for trapezoid\n",
        "vertices = np.array([[(dx1, ysize), (dx2, dy), (xsize - dx2, dy), (xsize - dx1, ysize)]], dtype=np.int32)\n",
        "\n",
        "# Converting image to grayscale\n",
        "grey = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Applying a gaussian blur mask on the gray image\n",
        "blur = cv2.GaussianBlur(grey, (5, 5), 0)\n",
        "\n",
        "# detecting edges in the image\n",
        "edges = cv2.Canny(blur, 25, 100)\n",
        "\n",
        "# Defining the region  of interest\n",
        "mask = np.zeros_like(edges)\n",
        "cv2.fillPoly(mask, vertices, 255)\n",
        "masked = cv2.bitwise_and(edges, mask)\n",
        "\n",
        "mask = np.zeros_like(frame).astype(np.uint8)\n",
        "cv2.fillPoly(mask, [vertices], (255,255,255))\n",
        "img_r_2= cv2.bitwise_and(mask,frame)\n",
        "\n",
        "new_img=cv2.bitwise_and(img_r_2,img_r_2,mask=masked)\n",
        "new_img=cv2.cvtColor(new_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Performing Hough transform to detect lanes\n",
        "lines = cv2.HoughLinesP(new_img, 1, np.pi/180, 40, np.array([]), minLineLength=200, maxLineGap=50)\n",
        "hough_image = np.zeros((*new_img.shape, 3), dtype=np.uint8)\n",
        "\n",
        "# for line in lines:\n",
        "#     x1,y1,x2,y2 = line[0]\n",
        "#     cv2.line(img_r_2,(x1,y1),(x2,y2),(0,255,0),2)\n",
        "# cv2_imshow(masked)\n"
      ],
      "metadata": {
        "id": "kXmIa_7elK_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Source points for homography.\n",
        "bird_eye_coords_= np.float32([[410,335], [535, 334], [780, 479], [150, 496]])\n",
        "# bird_eye_coords_=np.float32([[422,321],[540,330],[790,485],[80,500]])\n",
        "# Destination points for homography\n",
        "world_coords_ = np.float32([[50, 0], [250, 0], [250, 500], [0, 500]])\n",
        "\n",
        "h_, mask = cv2.findHomography( bird_eye_coords_,world_coords_,cv2.RANSAC,5.0)\n",
        "\n",
        "warped = cv2.warpPerspective(masked,h_,(300,600),flags=cv2.INTER_LINEAR)"
      ],
      "metadata": {
        "id": "0o85w9lPm9KY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gray = cv2.cvtColor(img_erosion3,cv2.COLOR_BGR2GRAY)\n",
        "# blur = cv2.GaussianBlur(gray,(1,1),1000)\n",
        "# flag, thresh = cv2.threshold(blur, 80, 255, cv2.THRESH_BINARY)\n",
        "edges = cv2.Canny(img_dilation2,0,255,apertureSize = 7)\n",
        "lines = cv2.HoughLinesP(edges,1,np.pi/180,100,minLineLength=10,maxLineGap=15)\n",
        "imgHoughed = target.copy()\n",
        "for line in lines:\n",
        "    x1,y1,x2,y2 = line[0]\n",
        "    cv2.line(imgHoughed,(x1,y1),(x2,y2),(0,255,0),2)\n",
        "cv2_imshow(imgHoughed)"
      ],
      "metadata": {
        "id": "fyLFCJUZcMtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hsv_frame = cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
        "\n",
        "# Mask the grey of the tarmac\n",
        "hsv_frame = cv2.GaussianBlur(hsv_frame,(1,1),1000)\n",
        "mask = cv2.inRange(hsv_frame, (0,10,30), (179,50,210))\n",
        "\n",
        "target = cv2.bitwise_and(frame,frame, mask=mask)\n",
        "cv2_imshow(target)"
      ],
      "metadata": {
        "id": "KNIMU1hNX6eN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepocess\n",
        "# gray = cv2.cvtColor(target,cv2.COLOR_BGR2GRAY)\n",
        "# blur = cv2.GaussianBlur(gray,(1,1),1000)\n",
        "# flag, thresh = cv2.threshold(blur, 80, 255, cv2.THRESH_BINARY)\n",
        "# Find contours\n",
        "contours, hierarchy = cv2.findContours(combined_image,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
        "contours = sorted(contours, key=cv2.contourArea,reverse=True)\n",
        "# Select long perimeters only\n",
        "perimeters = [cv2.arcLength(contours[i],True) for i in range(len(contours))]\n",
        "listindex=[i for i in range(15) if perimeters[i]>perimeters[0]/2]\n",
        "numcards=len(listindex)\n",
        "# Show image\n",
        "imgcont = target.copy()\n",
        "[cv2.drawContours(imgcont, [contours[i]], 0, (0,255,0), 5) for i in listindex]\n",
        "cv2_imshow(imgcont)"
      ],
      "metadata": {
        "id": "8KyggCVWixJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "height, width, depth = frame.shape\n",
        "\n",
        "color = ('b','g','r')\n",
        "for channel,col in enumerate(color):\n",
        "    histr = cv2.calcHist([frame],[channel],None,[256],[0,256])\n",
        "    plt.plot(histr,color = col)\n",
        "    plt.xlim([0,256])\n",
        "plt.title('Histogram for color scale picture')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-gJAL7HUG3d2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_lines(image, lines, color=[255, 0, 0], thickness=2):\n",
        "    for line in lines:\n",
        "        for x1,y1,x2,y2 in line:\n",
        "            cv2.line(image, (x1, y1), (x2, y2), color, thickness)"
      ],
      "metadata": {
        "id": "-wD5VJDVf0WW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspirations and sources\n",
        "* https://github.com/bharadwaj-chukkala/Road-Lanes-detection-and-Turn-Prediction-using-Sliding-Window-Algorithm/blob/master/Lane_Detection.py\n",
        "* https://github.com/silenc3502/PyOCVLaneDetect/blob/master/P1.ipynb\n",
        "* https://github.com/silenc3502/PyAdvancedLane/blob/master/doit.ipynb\n",
        "* https://www.sciencedirect.com/science/article/pii/S2214785320373302?casa_token=9_yFfncWoRIAAAAA:LoAM-vsl4Sb2JOpQ2cYtQyZY7sadoVVX5wIujeV3-rHMFDT6AljVKooSvG-BQZH_51Ro2LwJng#f0040\n",
        "* https://medium.com/@ldesegur/a-lane-detection-approach-for-self-driving-vehicles-c5ae1679f7ee\n",
        "* https://opencv.org/evaluating-opencvs-new-ransacs/\n"
      ],
      "metadata": {
        "id": "2xh5iMc1uA9H"
      }
    }
  ]
}